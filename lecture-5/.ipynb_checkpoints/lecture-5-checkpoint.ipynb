{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning vs unsupervised learning\n",
    "\n",
    "We have seen that data analysis is in big part about constructing models out of a given data, and we use these models mostly to make predictions on new data points.  \n",
    "\n",
    "![model](images/model.png)\n",
    "\n",
    "## Supervised learning\n",
    "\n",
    "[Last week](../lecture-4/lecture-4.ipynb) we have looked at [regression models](https://onlinecourses.science.psu.edu/stat501/node/250/). In the simplest cases, the data suitable for regression consists of instances of sequences of predictors (independent variables) of a fixed length $(x_1,\\ldots,x_n)$ and instances of explonatory (dependent) variables $y_i$.  We then constructed a *linear model* of the form\n",
    "$$ y \\sim \\alpha\\cdot\\mathbf{x} + \\beta $$\n",
    "where $\\mathbf{x}$ denotes a predictor and $y$ denotes a dependent variable, and $\\alpha$ and $\\beta$ are the model parameters.\n",
    "\n",
    "If you look at how we constructed our model, you will see that we must have samples of **expected output** for a collection of inputs.  Any model that requires that we have a collection of inputs and expected outputs is called a **supervised learning model**.  Thus we can also measure **the fit**. As a matter of fact, we constructed our model by optimizing the error. \n",
    "\n",
    "$$ RSS(\\alpha,\\beta) = \\sum_{i=1}^N\\left(y_i - \\beta - \\sum_{j=1}^n \\alpha_j x_{ij}\\right)^2 $$\n",
    "\n",
    "*The error* in this case is the sum of the squares of the differences between the expected out put and the predicted output coming from the model.\n",
    "\n",
    "The alternative to this model is an **unsupervised learning model**.\n",
    "\n",
    "## Unsupervised learning\n",
    "\n",
    "In unsupervised learning, we have a collection of data points but we do not know what the expected output is.  The learning process (the process of constructing a model) looks at the data and infers the model by looking at the internal structure, internal similarities and differences.  The only job that the analyst do in such cases is to set the *shape* of the model.  The rest is taken care of by the algorithm dictated by the choice we made.\n",
    "\n",
    "![clusters](images/clusters.png)\n",
    "\n",
    "## An example: k-nn vs k-means\n",
    "\n",
    "Consider the example dataset whose picture is given above. We would like to separate the dataset into distinct clusters.\n",
    "\n",
    "### k-nn (k-nearest neighbor)\n",
    "\n",
    "The k-nearest neighbor is a supervised classification algorithm. A classification problem is about finding a function\n",
    "$$ f\\colon D \\to \\{label_1,\\ldots, label_m \\} $$\n",
    "that labels any given data point $x\\in D$ with a specific label $f(x)$.\n",
    "The algorithm takes a collection of data points $(x_i)$ and a finite set of determined $m$ labels $y_1,\\ldots,y_m$.  Then it constructs a model, i.e. a function, which can determine a label for any new point whose label is to be decided.\n",
    "\n",
    "In the example above, we have a collection of data points in $\\mathbb{R}^2$ and our labels are the colors these points are associated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xs</th>\n",
       "      <th>ys</th>\n",
       "      <th>cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.773568</td>\n",
       "      <td>-2.352066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.898887</td>\n",
       "      <td>-3.367362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.239500</td>\n",
       "      <td>-1.666473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.821159</td>\n",
       "      <td>-1.967975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.474336</td>\n",
       "      <td>-2.273545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.747570</td>\n",
       "      <td>-1.386538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.416366</td>\n",
       "      <td>-1.409914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.885088</td>\n",
       "      <td>0.093531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.179505</td>\n",
       "      <td>-3.282915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.039148</td>\n",
       "      <td>0.295615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          xs        ys  cs\n",
       "1  -3.773568 -2.352066   0\n",
       "2  -0.898887 -3.367362   0\n",
       "3   1.239500 -1.666473   0\n",
       "4  -0.821159 -1.967975   0\n",
       "5  -0.474336 -2.273545   0\n",
       "6  -0.747570 -1.386538   0\n",
       "7  -1.416366 -1.409914   0\n",
       "8  -0.885088  0.093531   0\n",
       "9  -0.179505 -3.282915   0\n",
       "10  1.039148  0.295615   0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = pd.read_csv(\"data/clusters.csv\")\n",
    "points.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only parameters the k-nearest neighbor algorithm has are an odd positive integer k, and a distance function.  In the this algorithm, the model takes an unlabelled point $\\mathbf{x}$ and then find the k-closest points $\\mathbf{x}'_1,\\ldots,\\mathbf{x}'_k$ whose labels are known. Then the algorithm takes a vote among these points, i.e. counts the occurances of labels. Whichever label wins is assigned as the label for the point $\\mathbb{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(points.iloc[:,0:1], points.iloc[:,2], test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39  5  2]\n",
      " [15 14  3]\n",
      " [ 0  5 82]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "classifier.fit(Xtrain, Ytrain)\n",
    "predicted = classifier.predict(Xtest)\n",
    "print(confusion_matrix(Ytest,predicted))\n",
    "accuracy_score(Ytest,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  6  2]\n",
      " [14 12  6]\n",
      " [ 1  2 84]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8121212121212121"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=9, metric='minkowski')\n",
    "classifier.fit(Xtrain, Ytrain)\n",
    "predicted = classifier.predict(Xtest)\n",
    "print(confusion_matrix(Ytest,predicted))\n",
    "accuracy_score(Ytest,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa\n",
       "5  5.4  3.9  1.7  0.4  Iris-setosa\n",
       "6  4.6  3.4  1.4  0.3  Iris-setosa\n",
       "7  5.0  3.4  1.5  0.2  Iris-setosa\n",
       "8  4.4  2.9  1.4  0.2  Iris-setosa\n",
       "9  4.9  3.1  1.5  0.1  Iris-setosa"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(\"data/iris.csv\",header=-1)\n",
    "iris.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(iris.iloc[:,0:3], iris.iloc[:,4], test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0  0]\n",
      " [ 0 23  1]\n",
      " [ 0  3 23]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9466666666666667"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "classifier.fit(Xtrain, Ytrain)\n",
    "predicted = classifier.predict(Xtest)\n",
    "print(confusion_matrix(Ytest,predicted))\n",
    "accuracy_score(Ytest,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means\n",
    "\n",
    "The next algorithm, k-means, is an unsupervised clustering algorithm. Clustering algorithms, unlike classification algorithms, do not have a preconceived notion of *labels*.  Instead, they try to split the data points into disjoint clusters by looking at their internal structures. Again, there are two parameters: the number of clusters and a distance function.\n",
    "\n",
    "Here is how the algorithm works:\n",
    "\n",
    "1. Initially, we randomly place cluster centers $c_1,\\ldots,c_k$\n",
    "2. We go over all of the points $x\\in D$ in our dataset. We determine which center $c_i$ is closest to $x$, and then assign cluster label $i$ to $x$\n",
    "3. When Step (2) is done, we recalculate the center of each cluster $i$.\n",
    "4. Repeat Steps (2) and (3) until cluster centers stabilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  7]\n",
      " [ 0 25  0]\n",
      " [ 4  0 20]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8533333333333334"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KMeans(n_clusters=3)\n",
    "classifier.fit(Xtest)\n",
    "predicted = classifier.predict(Xtest)\n",
    "labels = {\"Iris-setosa\":1, \"Iris-versicolor\":2, \"Iris-virginica\":0}\n",
    "real = Ytest.map(lambda x: labels[x])\n",
    "print(confusion_matrix(real,predicted))\n",
    "accuracy_score(real,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(points.iloc[:,0:1], points.iloc[:,2], test_size=0.5, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[123   1   0]\n",
      " [  9  38  12]\n",
      " [  2  21  44]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KMeans(n_clusters=3, random_state=9)\n",
    "classifier.fit(Xtest)\n",
    "predicted = classifier.predict(Xtest)\n",
    "transform = [2,1,0]\n",
    "real = Ytest.map(lambda x: transform[x])\n",
    "print(confusion_matrix(real,predicted))\n",
    "accuracy_score(real,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example: Naive Bayes Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(glob.glob('data/corpus/spm*')[0],\"r\") as f:\n",
    "    raw = re.sub(r'[^a-zA-Z ]','',f.read()).lower().split(' ')\n",
    "    res = Counter(raw)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "raw.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
